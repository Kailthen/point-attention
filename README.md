# DAPnet: A double attention convolutional network for segmentation of point clouds

## Abstract 

LiDAR point cloud, which consists of irregularly distributed points in the 3D space, has a complex structure and the 3D semantic labeling of it is a challenging task. Existing methods adopt data transformations without fully exploring contextual features, which are less efficient and accurate in capturing the complexity of point clouds. In this study, we propose a novel double attention convolutional network, called DAPnet, which can be directly applied to processing LiDAR point clouds by combining geometric and contextual features to generate better segmentation results. The double attention module includes point attention module and group attention module originating from the self-attention mechanism is used to model the interdependencies between neighboring or groups of points in order to extract contextual features of ground objects with various shapes and scales. These extracted context features represent the long-range dependencies between the data and are beneficial to reducing the scale diversity of point cloud objects. We evaluate our method based on the ISPRS 3D Semantic Labeling Contest dataset and find that our model outperforms the benchmark by 85.2\% with an overall accuracy of 90.7\%. The improvements over powerline and car are 7.5\% and 13\%. By conducting ablation comparison, we find that the point attention module is more effective for the overall improvement of the model than the group attention module, and the incorporation of the double attention module has an average of 7\% improvement on the pre-class accuracy of the classes. Moreover, the adoption of the double attention module consumes a similar training time as the one without the attention module for model convergence. The experimental result shows the effectiveness and efficiency of DAPnet for the segmentation of LiDAR point clouds.
